{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ee6739a",
   "metadata": {},
   "source": [
    "# Creando dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5516f199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca87c11",
   "metadata": {},
   "source": [
    "Deteccion de microparadas\n",
    "Flujo:\n",
    "1. Primero generaremos csv de microparadas para cada objeto\n",
    "2. Como seran csv entonces ya "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cbb2038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id         Fecha y hora               posición  Distancia (m)  \\\n",
      "0   1  29/09/2025 22:15:14  S12 04.069 W77 03.038              0   \n",
      "1   2  29/09/2025 22:16:14  S12 04.134 W77 02.957            191   \n",
      "2   3  29/09/2025 22:16:44  S12 04.137 W77 02.956              5   \n",
      "\n",
      "  Tiempo de registro (s)  Velocidad (km/h)  \n",
      "0                0:00:00                 0  \n",
      "1                0:01:00                11  \n",
      "2                0:00:30                 1  \n"
     ]
    }
   ],
   "source": [
    "df_1 = pd.read_csv(\"../BD_Innovathon/Objeto_1_ES_pos.csv\")\n",
    "df_2 = pd.read_csv(\"../BD_Innovathon/Objeto_2_ES_pos.csv\")\n",
    "print(df_2.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16956a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_microparadas_by_object(dataframe_object, object_id):\n",
    "    # for para cada registro    \n",
    "    dataframe_object['is_microparada'] = dataframe_object['Velocidad (km/h)'].apply(lambda x: 1 if x < 6 else 0)\n",
    "    ultima_fila = dataframe_object.iloc[-1]\n",
    "    alerta = bool(ultima_fila['is_microparada'] == 1)\n",
    "\n",
    "    # Respuesta tipo JSON para la mini app\n",
    "    result = {\n",
    "        \"objeto_id\": object_id,\n",
    "        \"alerta\": alerta,\n",
    "        \"fecha_hora\": str(ultima_fila['Fecha y hora']),\n",
    "        \"posicion\": ultima_fila['posición'],\n",
    "        \"velocidad\": ultima_fila['Velocidad (km/h)']\n",
    "    }\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36d423c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objeto_id': 1, 'alerta': True, 'fecha_hora': '29/09/2025 23:19:19', 'posicion': 'S11 59.972 W76 49.870', 'velocidad': np.int64(0)}\n"
     ]
    }
   ],
   "source": [
    "dft_1 = detect_microparadas_by_object(df_1, 1)\n",
    "print(dft_1)\n",
    "#dft_2 = detect_microparadas_by_object(df_2, objeto_id=2) \n",
    "#print(dft_2.shape)\n",
    "#dft_2 = detect_microparadas_by_object(df_2, objeto_id=2)\n",
    "#dft_3 = detect_microparadas_by_object(df_3, objeto_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49afe48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /home/jazmin/Escritorio/AlertaVIAl/.venv/lib/python3.12/site-packages (from scikit-learn) (2.3.3)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Using cached scipy-1.16.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached scipy-1.16.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.16.2 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c0856f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 1. Cargar datos y detectar microparadas\n",
    "df = pd.read_csv(\"../BD_Innovathon/Objeto_1_ES_pos.csv\")\n",
    "df['is_microparada'] = df['Velocidad (km/h)'].apply(lambda v: 1 if v < 6 else 0)\n",
    "df['hora'] = pd.to_datetime(df['Fecha y hora'], dayfirst=True).dt.hour\n",
    "df['dia_semana'] = pd.to_datetime(df['Fecha y hora'], dayfirst=True).dt.dayofweek\n",
    "\n",
    "\n",
    "# 2. Generar etiquetas (congestión si hay muchas microparadas en un lugar/hora)\n",
    "trafico = df.groupby(['posición','hora']).agg({'is_microparada':'sum'}).reset_index()\n",
    "trafico['y'] = (trafico['is_microparada'] >= 3).astype(int)\n",
    "\n",
    "# 3. Variables predictoras\n",
    "X = trafico[['hora']]\n",
    "y = trafico['y']\n",
    "\n",
    "# 4. Modelo simple\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "modelo = RandomForestClassifier()\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# 5. Predicción\n",
    "predicciones = modelo.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86e9502d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eee58772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis de datos:\n",
      "Total de microparadas: 25\n",
      "Porcentaje de microparadas: 30.12%\n",
      "\n",
      "Distribución por hora:\n",
      "      count  sum      mean\n",
      "hora                      \n",
      "22       62   18  0.290323\n",
      "23       21    7  0.333333\n",
      "\n",
      "Datos de tráfico agrupados:\n",
      "                posición  hora  is_microparada  y\n",
      "0  S11 59.937 W76 50.025    23               0  0\n",
      "1  S11 59.938 W76 50.023    23               1  0\n",
      "2  S11 59.938 W76 50.028    23               0  0\n",
      "3  S11 59.972 W76 49.870    23               3  1\n",
      "4  S11 59.972 W76 49.872    23               3  1\n",
      "5  S11 59.974 W76 49.878    23               0  0\n",
      "6  S11 59.975 W76 49.869    23               0  0\n",
      "7  S12 00.021 W76 49.986    23               0  0\n",
      "8  S12 00.021 W76 49.989    23               0  0\n",
      "9  S12 00.029 W76 49.994    23               0  0\n",
      "\n",
      "Etiquetas de congestión (y=1): 3\n",
      "Total de observaciones: 73\n"
     ]
    }
   ],
   "source": [
    "# Analizar los datos para entender mejor el problema\n",
    "print(\"Análisis de datos:\")\n",
    "print(f\"Total de microparadas: {df['is_microparada'].sum()}\")\n",
    "print(f\"Porcentaje de microparadas: {df['is_microparada'].mean()*100:.2f}%\")\n",
    "print(\"\\nDistribución por hora:\")\n",
    "print(df.groupby('hora')['is_microparada'].agg(['count', 'sum', 'mean']))\n",
    "\n",
    "print(\"\\nDatos de tráfico agrupados:\")\n",
    "print(trafico.head(10))\n",
    "print(f\"\\nEtiquetas de congestión (y=1): {trafico['y'].sum()}\")\n",
    "print(f\"Total de observaciones: {len(trafico)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49201481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import argparse\n",
    "import re\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# === Helpers ===\n",
    "\n",
    "POS_RE = re.compile(\n",
    "    r'^\\s*([NS])\\s*(\\d{1,2})\\s+(\\d{1,2}\\.\\d+)\\s+([EWOW])\\s*(\\d{1,3})\\s+(\\d{1,2}\\.\\d+)\\s*$',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "# Nota: permitimos 'W' normal; el grupo [EWOW] incluye una 'O' por si viniera \"Oeste\" (O).\n",
    "# Si tu data siempre es W, igual funciona.\n",
    "\n",
    "def pos_sw_to_latlon(pos_str: str):\n",
    "    \"\"\"\n",
    "    Convierte 'S12 01.393 W76 54.690' → (lat, lon) en decimales.\n",
    "    lat = -(12 + 1.393/60) por 'S'\n",
    "    lon = -(76 + 54.690/60) por 'W'\n",
    "    \"\"\"\n",
    "    if pd.isna(pos_str):\n",
    "        return (None, None)\n",
    "    s = str(pos_str).strip()\n",
    "    m = POS_RE.match(s)\n",
    "    if not m:\n",
    "        # Intento alternativo: reemplazar 'O' por 'W' y reintentar\n",
    "        s2 = s.replace(' O', ' W').replace(' o', ' w')\n",
    "        m = POS_RE.match(s2)\n",
    "        if not m:\n",
    "            return (None, None)\n",
    "\n",
    "    hemi_lat, deg_lat, min_lat, hemi_lon, deg_lon, min_lon = m.groups()\n",
    "    deg_lat = float(deg_lat); min_lat = float(min_lat)\n",
    "    deg_lon = float(deg_lon); min_lon = float(min_lon)\n",
    "\n",
    "    lat = deg_lat + (min_lat / 60.0)\n",
    "    lon = deg_lon + (min_lon / 60.0)\n",
    "\n",
    "    hemi_lat = hemi_lat.upper()\n",
    "    hemi_lon = hemi_lon.upper().replace('O', 'W')  # tratar 'O' (Oeste) como 'W'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if hemi_lat == 'S':\n",
    "        lat = -lat\n",
    "    elif hemi_lat == 'N':\n",
    "        lat = +lat\n",
    "    else:\n",
    "        return (None, None)\n",
    "\n",
    "    if hemi_lon == 'W':\n",
    "        lon = -lon\n",
    "    elif hemi_lon == 'E':\n",
    "        lon = +lon\n",
    "    else:\n",
    "        return (None, None)\n",
    "\n",
    "    return (round(lat, 9), round(lon, 9))  # 9 decimales ≈ precisión sub-métrica\n",
    "\n",
    "def parse_datetime_peru(dt_str: str):\n",
    "    \"\"\"\n",
    "    Convierte '29/09/2025 22:15:02' → (año, mes, día, hora, minuto, segundo)\n",
    "    Formato esperado: DD/MM/YYYY HH:MM:SS\n",
    "    \"\"\"\n",
    "    if pd.isna(dt_str):\n",
    "        return (None,)*6\n",
    "    s = str(dt_str).strip()\n",
    "    try:\n",
    "        dt = datetime.strptime(s, \"%d/%m/%Y %H:%M:%S\")\n",
    "        return dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second\n",
    "    except ValueError:\n",
    "        # fallback común: si hubiera ceros a la izquierda omitidos\n",
    "        try:\n",
    "            dt = pd.to_datetime(s, dayfirst=True, errors='raise')\n",
    "            return dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second\n",
    "        except Exception:\n",
    "            return (None,)*6\n",
    "\n",
    "def hms_to_seconds(hms_str: str):\n",
    "    \"\"\"\n",
    "    Convierte 'H:MM:SS' (p.ej. '0:01:00') → 60 (segundos).\n",
    "    Si es '0' o vacío → 0.\n",
    "    \"\"\"\n",
    "    if pd.isna(hms_str):\n",
    "        return 0\n",
    "    s = str(hms_str).strip()\n",
    "    if s in (\"\", \"0\", \"00:00:00\", \"0:00:00\"):\n",
    "        return 0\n",
    "    parts = s.split(':')\n",
    "    try:\n",
    "        if len(parts) == 3:\n",
    "            h, m, sec = int(parts[0]), int(parts[1]), int(round(float(parts[2])))\n",
    "            return h*3600 + m*60 + sec\n",
    "        elif len(parts) == 2:  # MM:SS\n",
    "            m, sec = int(parts[0]), int(round(float(parts[1])))\n",
    "            return m*60 + sec\n",
    "        elif len(parts) == 1:  # Solo segundos\n",
    "            return int(round(float(parts[0])))\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Último recurso: intentar con pandas\n",
    "    try:\n",
    "        td = pd.to_timedelta(s)\n",
    "        return int(td.total_seconds())\n",
    "    except Exception:\n",
    "        return 0\n",
    "\n",
    "# === Main ===\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser(description=\"Prepara micro-paradas: lat/lon, descomposición de fecha y segundos del tiempo de registro.\")\n",
    "    ap.add_argument(\"--input\", \"-i\", required=True, help=\"Ruta del CSV de entrada.\")\n",
    "    ap.add_argument(\"--output\", \"-o\", required=True, help=\"Ruta del CSV de salida.\")\n",
    "    ap.add_argument(\"--encoding\", default=\"utf-8-sig\", help=\"Encoding del CSV (por defecto utf-8-sig).\")\n",
    "    ap.add_argument(\"--sep\", default=\",\", help=\"Separador del CSV (por defecto ,).\")\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    # Nombres exactos de columnas esperadas:\n",
    "    COL_ID = \"Id\"\n",
    "    COL_FECHA = \"Fecha y hora\"\n",
    "    COL_POS = \"posición\"\n",
    "    COL_DIST = \"Distancia (m)\"\n",
    "    COL_TREG = \"Tiempo de registro (s)\"\n",
    "    COL_VEL = \"Velocidad (km/h)\"\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(args.input, encoding=args.encoding, sep=args.sep)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] No pude leer el CSV: {e}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Validación mínima de columnas\n",
    "    expected = {COL_ID, COL_FECHA, COL_POS, COL_DIST, COL_TREG, COL_VEL}\n",
    "    missing = expected - set(df.columns)\n",
    "    if missing:\n",
    "        print(f\"[ERROR] Faltan columnas en el CSV: {missing}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    # ---- Conversión de posición a lat/lon ----\n",
    "    latitudes = []\n",
    "    longitudes = []\n",
    "    for pos in df[COL_POS]:\n",
    "        lat, lon = pos_sw_to_latlon(pos)\n",
    "        latitudes.append(lat)\n",
    "        longitudes.append(lon)\n",
    "    df[\"Latitud\"]  = latitudes\n",
    "    df[\"Longitud\"] = longitudes\n",
    "\n",
    "    # ---- Descomponer fecha y hora ----\n",
    "    anos, meses, dias, horas, minutos, segundos = [], [], [], [], [], []\n",
    "    for dt_str in df[COL_FECHA]:\n",
    "        y, mo, d, h, mi, se = parse_datetime_peru(dt_str)\n",
    "        anos.append(y); meses.append(mo); dias.append(d)\n",
    "        horas.append(h); minutos.append(mi); segundos.append(se)\n",
    "    df[\"Año\"] = anos\n",
    "    df[\"Mes\"] = meses\n",
    "    df[\"Día\"] = dias\n",
    "    df[\"Hora\"] = horas\n",
    "    df[\"Minuto\"] = minutos\n",
    "    df[\"Segundo\"] = segundos\n",
    "\n",
    "    # ---- Tiempo de registro a segundos ----\n",
    "    df[\"TiempoRegistro_Seg\"] = [hms_to_seconds(x) for x in df[COL_TREG]]\n",
    "\n",
    "    # Orden sugerido de columnas (puedes ajustar):\n",
    "    ordered_cols = [\n",
    "        COL_ID,\n",
    "        COL_FECHA, \"Año\", \"Mes\", \"Día\", \"Hora\", \"Minuto\", \"Segundo\",\n",
    "        COL_POS, \"Latitud\", \"Longitud\",\n",
    "        COL_DIST, COL_TREG, \"TiempoRegistro_Seg\",\n",
    "        COL_VEL\n",
    "    ]\n",
    "    # Mantener también cualquier otra columna extra (si existiera)\n",
    "    tail_cols = [c for c in df.columns if c not in ordered_cols]\n",
    "    df = df[ordered_cols + tail_cols]\n",
    "\n",
    "    # Guardar\n",
    "    try:\n",
    "        df.to_csv(args.output, index=False, encoding=\"utf-8-sig\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] No pude escribir el CSV de salida: {e}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(f\"[OK] Archivo generado: {args.output}\")\n",
    "    # Nota: si ves lat/long = NaN en algunas filas, revisa el formato exacto de 'posición'.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
